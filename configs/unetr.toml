# python unetr.py --config configs/unetr.toml 
COMMENT = "Run 23: Patch 2 w/augmented data 150 epochs, 128 feature size, .75 mask ration"
LOG_DIR = "logs/unetr/23/"

RANDOM_SEED = 42

BATCH_SIZE = 16 
NUM_EPOCHS = 150

# --- OPTIMIZER ---
BETA_1 = 0.90
BETA_2 = 0.95  # FB ViTMAE article (0.95)
WEIGHT_DECAY = 0.0
LEARNING_RATE = 1.0e-5


# --> UNETR MODEL <-- 
NUM_CLASSES = 16
FEATURE_SIZE = 128 
IN_CHANNEL = 16 
SPATIAL_DIMS = 2
RES_BLOCK = true 


SAVE_MODELS = 1

# sideswipe.research.cs.dal.ca
TRAIN_DATASET = '/home/mhill/Projects/cathepsin/data/unet_training_dataset.npz'
VALID_DATASET = '/home/mhill/Projects/cathepsin/data/unet_validation_dataset.npz'
TEST_DATASET = '/home/mhill/Projects/cathepsin/data/unet_testing_dataset.npz'

PRE_TRAINED_MODEL  = '/home/mhill/Projects/cathepsin/logs/vitmae/14/model.pth' 
# PRE_TRAINED_MODEL = '/home/mhill/Projects/cathepsin/logs/vitmae/09/model.pth' #4x4 
# PRE_TRAINED_MODEL = '/home/mhill/Projects/cathepsin/logs/vitmae/17/model.pth' #8x8 

